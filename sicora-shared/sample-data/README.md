# ğŸ“Š Shared Data - Carga Masiva Multistack

**PropÃ³sito**: Directorio compartido para carga masiva de datos accesible por todos los 6 stacks tecnolÃ³gicos del proyecto SICORA-APP Backend Multistack.

**Ãšltima actualizaciÃ³n**: 15 de junio de 2025

---

## ğŸ¯ **OBJETIVOS**

### **Consistencia Multistack**
- Todos los stacks acceden a los mismos archivos de datos
- Formato estandarizado de importaciÃ³n/exportaciÃ³n
- Validaciones consistentes independientemente del stack
- Esquemas unificados para todas las entidades

### **CentralizaciÃ³n de Datos**
- Ãšnica fuente de verdad para datos de prueba
- Templates reutilizables para carga masiva
- Samples consistentes para desarrollo
- Esquemas validados para todas las tecnologÃ­as

---

## ğŸ“ **ESTRUCTURA DEL DIRECTORIO**

```
shared-data/
â”œâ”€â”€ ğŸ“‚ imports/           # Archivos para importaciÃ³n masiva
â”‚   â”œâ”€â”€ users/           # Datos de usuarios
â”‚   â”œâ”€â”€ schedules/       # Datos de horarios
â”‚   â”œâ”€â”€ attendance/      # Datos de asistencia
â”‚   â”œâ”€â”€ evaluations/     # Datos de evaluaciones
â”‚   â”œâ”€â”€ knowledge-base/  # Documentos para KB
â”‚   â””â”€â”€ ai-training/     # Datos para entrenamiento IA
â”œâ”€â”€ ğŸ“‚ templates/        # Plantillas CSV/JSON con headers
â”‚   â”œâ”€â”€ users.csv
â”‚   â”œâ”€â”€ schedules.csv
â”‚   â”œâ”€â”€ attendance.csv
â”‚   â””â”€â”€ evaluations.csv
â”œâ”€â”€ ğŸ“‚ exports/          # Datos exportados (por stack)
â”‚   â”œâ”€â”€ fastapi/
â”‚   â”œâ”€â”€ go/
â”‚   â”œâ”€â”€ express/
â”‚   â”œâ”€â”€ nextjs/
â”‚   â”œâ”€â”€ java/
â”‚   â””â”€â”€ kotlin/
â”œâ”€â”€ ğŸ“‚ samples/          # Datos de ejemplo para desarrollo
â”‚   â”œâ”€â”€ small/          # Datasets pequeÃ±os (10-100 registros)
â”‚   â”œâ”€â”€ medium/         # Datasets medianos (1K-10K registros)
â”‚   â””â”€â”€ large/          # Datasets grandes (100K+ registros)
â”œâ”€â”€ ğŸ“‚ schemas/          # Esquemas de validaciÃ³n
â”‚   â”œâ”€â”€ json-schema/    # JSON Schema para validaciones
â”‚   â”œâ”€â”€ csv-specs/      # Especificaciones CSV
â”‚   â””â”€â”€ api-contracts/  # Contratos de API para bulk operations
â””â”€â”€ ğŸ“‹ README.md         # Este archivo
```

---

## ğŸ”§ **TECNOLOGÃAS SOPORTADAS**

### **Formatos de Datos**
- **CSV**: ImportaciÃ³n/exportaciÃ³n masiva
- **JSON**: APIs y intercambio de datos
- **Excel**: Compatibilidad con herramientas de oficina
- **XML**: Sistemas legacy y estÃ¡ndares
- **Parquet**: Datos grandes y anÃ¡lisis

### **Validaciones**
- **JSON Schema**: ValidaciÃ³n de estructura
- **CSV Schema**: ValidaciÃ³n de archivos CSV
- **Data Types**: ValidaciÃ³n de tipos por stack
- **Business Rules**: Reglas de negocio consistentes

---

## ğŸ“Š **ENTIDADES SOPORTADAS**

### **ğŸ” Usuarios (UserService)**
- **Archivos**: `users.csv`, `users.json`
- **Campos**: id, nombre, apellido, email, documento, rol, contraseÃ±a, ficha_id, programa
- **Validaciones**: Email Ãºnico, documento Ãºnico, polÃ­ticas de contraseÃ±a
- **Reglas SENA especÃ­ficas**: 
  - **Aprendices**: OBLIGATORIO ficha_id (7 dÃ­gitos), un aprendiz solo puede estar en una ficha
  - **Instructores/Admin/Coordinadores**: ficha_id debe ser null, programa indica especializaciÃ³n
- **Volumen**: Hasta 100K usuarios

### **ğŸ“… Horarios (ScheduleService)**
- **Archivos**: `schedules.csv`, `schedules.json`
- **Campos**: id, instructor_id, curso, fecha_inicio, fecha_fin, salon
- **Validaciones**: Conflictos de horario, disponibilidad de instructor
- **Volumen**: Hasta 50K horarios

### **ğŸ“ Asistencia (AttendanceService)**
- **Archivos**: `attendance.csv`, `attendance.json`
- **Campos**: id, schedule_id, student_id, timestamp, status
- **Validaciones**: Estudiante matriculado, horario vÃ¡lido
- **Volumen**: Hasta 1M registros de asistencia

### **ğŸ“Š Evaluaciones (EvalinService)**
- **Archivos**: `evaluations.csv`, `evaluations.json`
- **Campos**: id, instructor_id, student_id, criteria, scores, comments
- **Validaciones**: Criterios vÃ¡lidos, rangos de puntuaciÃ³n
- **Volumen**: Hasta 500K evaluaciones

### **ğŸ“š Base de Conocimiento (KbService)**
- **Archivos**: `documents/`, `categories.csv`
- **Campos**: id, title, content, category, tags, embeddings
- **Validaciones**: Contenido vÃ¡lido, categorÃ­as existentes
- **Volumen**: Hasta 100K documentos

### **ğŸ¤– Datos IA (AiService)**
- **Archivos**: `training-data/`, `prompts.json`
- **Campos**: id, input, expected_output, category, quality_score
- **Validaciones**: Calidad de datos, formato de prompts
- **Volumen**: Hasta 1M puntos de entrenamiento

---

## ğŸš€ **INTEGRACIÃ“N POR STACK**

### **ğŸ FastAPI (Python)**
```python
# Ejemplo de uso
import pandas as pd
from pathlib import Path

SHARED_DATA = Path("../../shared-data")
users_df = pd.read_csv(SHARED_DATA / "imports" / "users" / "users.csv")
```

### **âš¡ Go**
```go
// Ejemplo de uso
import (
    "encoding/csv"
    "path/filepath"
)

sharedDataPath := "../../shared-data"
usersFile := filepath.Join(sharedDataPath, "imports", "users", "users.csv")
```

### **ğŸ“± Express (Node.js)**
```javascript
// Ejemplo de uso
const path = require('path');
const csv = require('csv-parser');

const sharedDataPath = path.join(__dirname, '../../shared-data');
const usersFile = path.join(sharedDataPath, 'imports', 'users', 'users.csv');
```

### **ğŸš€ Next.js**
```typescript
// Ejemplo de uso
import path from 'path';
import { readFileSync } from 'fs';

const sharedDataPath = path.join(process.cwd(), '../../shared-data');
const usersFile = path.join(sharedDataPath, 'imports', 'users', 'users.csv');
```

### **â˜• Java (Spring Boot)**
```java
// Ejemplo de uso
import java.nio.file.Path;
import java.nio.file.Paths;

Path sharedDataPath = Paths.get("../../shared-data");
Path usersFile = sharedDataPath.resolve("imports/users/users.csv");
```

### **ğŸ”® Kotlin (Spring Boot)**
```kotlin
// Ejemplo de uso
import java.nio.file.Path
import java.nio.file.Paths

val sharedDataPath: Path = Paths.get("../../shared-data")
val usersFile = sharedDataPath.resolve("imports/users/users.csv")
```

---

## ğŸ“‹ **CONVENCIONES DE ARCHIVOS**

### **Nomenclatura**
- **Entidades**: Singular en inglÃ©s (`user.csv`, no `users.csv`)
- **Timestamps**: ISO 8601 UTC (`2025-06-15T18:30:00Z`)
- **IDs**: UUID v4 format
- **Fichas SENA**: 7 dÃ­gitos numÃ©ricos (ej. `2826503`)
- **Encoding**: UTF-8 con BOM
- **Line Endings**: LF (Unix style)

### **Estructura CSV**
```csv
# Header obligatorio
id,nombre,apellido,email,documento,rol,ficha_id,programa,created_at
# Datos con separador coma
uuid-v4,string,string,email,string,enum,7-digits|null,string,iso-datetime
```

### **Reglas de ValidaciÃ³n SENA**
- **Aprendices**: ficha_id OBLIGATORIO (7 dÃ­gitos), programa = nombre del programa de formaciÃ³n
- **Instructores**: ficha_id = null, programa = Ã¡rea de especializaciÃ³n
- **Admin/Coordinadores**: ficha_id = null, programa = rol especÃ­fico
- **Unicidad**: Un aprendiz solo puede estar matriculado en una ficha

### **Estructura JSON**
```json
{
  "metadata": {
    "version": "1.0",
    "created_at": "2025-06-15T18:30:00Z",
    "total_records": 1000,
    "schema_version": "users_v1.0"
  },
  "data": [
    {
      "id": "uuid-v4",
      "nombre": "string",
      "apellido": "string",
      "email": "email",
      "documento": "string",
      "rol": "enum",
      "created_at": "iso-datetime"
    }
  ]
}
```

---

## ğŸ” **VALIDACIONES COMUNES**

### **Pre-importaciÃ³n**
1. **Formato de archivo**: CSV/JSON vÃ¡lido
2. **Schema compliance**: Estructura correcta
3. **Data types**: Tipos de datos correctos
4. **Required fields**: Campos obligatorios presentes
5. **Unique constraints**: ValidaciÃ³n de unicidad

### **Durante importaciÃ³n**
1. **Business rules**: Reglas de negocio
2. **Foreign keys**: Referencias vÃ¡lidas
3. **Data integrity**: Integridad referencial
4. **Batch size**: Procesamiento por lotes
5. **Error handling**: Manejo de errores

### **Post-importaciÃ³n**
1. **Data verification**: VerificaciÃ³n de datos
2. **Counts validation**: ValidaciÃ³n de conteos
3. **Quality checks**: Verificaciones de calidad
4. **Audit logging**: Registro de auditorÃ­a
5. **Performance metrics**: MÃ©tricas de rendimiento

---

## ğŸ› ï¸ **HERRAMIENTAS DE DESARROLLO**

### **Generadores de Datos**
- **Faker libraries**: Datos sintÃ©ticos realistas
- **Data generators**: Herramientas especÃ­ficas por stack
- **Sample creators**: Creadores de datasets de prueba

### **Validadores**
- **CSV Validator**: ValidaciÃ³n de archivos CSV
- **JSON Schema Validator**: ValidaciÃ³n de JSON
- **Data Quality Checker**: Verificador de calidad

### **Convertidores**
- **CSV â†” JSON**: ConversiÃ³n entre formatos
- **Excel â†’ CSV**: ImportaciÃ³n desde Excel
- **Database â†’ CSV**: ExportaciÃ³n desde BD

---

## ğŸ“ˆ **MÃ‰TRICAS Y MONITOREO**

### **Performance**
- **Import speed**: Velocidad de importaciÃ³n por stack
- **Memory usage**: Uso de memoria durante carga
- **Error rates**: Tasas de error por tipo de dato
- **Processing time**: Tiempo de procesamiento total

### **Quality**
- **Data accuracy**: PrecisiÃ³n de datos importados
- **Completeness**: Completitud de datasets
- **Consistency**: Consistencia entre stacks
- **Validation success**: Ã‰xito de validaciones

---

## ğŸš€ **PRIMEROS PASOS**

### **1. Configurar acceso a shared-data**
```bash
# Desde cualquier stack
cd 01-fastapi  # o 02-go, 03-express, etc.
ls -la ../shared-data/  # Verificar acceso
```

### **2. Usar templates**
```bash
# Copiar template para personalizar
cp ../shared-data/templates/users.csv ./data/my-users.csv
```

### **3. Implementar carga masiva**
```bash
# Cada stack implementa su propio bulk loader
# que lee desde shared-data/imports/
```

### **4. Validar importaciÃ³n**
```bash
# Usar esquemas de shared-data/schemas/
# para validar antes de importar
```

---

## ğŸ“ **SOPORTE Y CONTRIBUCIÃ“N**

### **Agregar nuevas entidades**
1. Crear directorio en `imports/`
2. Agregar template en `templates/`
3. Definir schema en `schemas/`
4. Crear samples en `samples/`
5. Documentar en este README

### **Reportar problemas**
- **Issues de formato**: Esquemas incorrectos
- **Performance**: Carga lenta en algÃºn stack
- **Inconsistencias**: Comportamiento diferente entre stacks

---

**Este directorio es la base comÃºn para toda la funcionalidad de carga masiva del proyecto multistack.**

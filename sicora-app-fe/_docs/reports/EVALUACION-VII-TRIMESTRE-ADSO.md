# ğŸ“ **EVALUACIÃ“N PRÃCTICA - VII TRIMESTRE ADSO**

**Asignatura:** AnÃ¡lisis y Desarrollo de Software  
**Trimestre:** VII  
**DuraciÃ³n:** 1 semana (7 dÃ­as calendario)  
**Modalidad:** PrÃ¡ctica individual con acceso al repositorio del proyecto  
**Stack:** FastAPI (Python) - UserService y EvalinService

---

## ğŸ¯ **OBJETIVOS DE APRENDIZAJE**

Al finalizar esta evaluaciÃ³n, el estudiante serÃ¡ capaz de:

1. **Analizar** la arquitectura Clean Architecture implementada en microservicios reales
2. **Implementar** nuevas funcionalidades siguiendo los patrones establecidos
3. **Aplicar** buenas prÃ¡cticas de desarrollo backend con FastAPI
4. **Validar** y **testear** cÃ³digo siguiendo estÃ¡ndares profesionales
5. **Documentar** APIs usando OpenAPI/Swagger
6. **Integrar** servicios mediante comunicaciÃ³n entre microservicios

---

## ğŸ“š **CONTEXTO Y RECURSOS**

### **ğŸ“– DocumentaciÃ³n de Apoyo**

- **ğŸ“‹ [Instrucciones Detalladas Paso a Paso](EVALUACION-VII-TRIMESTRE-INSTRUCCIONES-DETALLADAS.md)** â† **Â¡EMPIEZA AQUÃ!**
- **ğŸ’» [Plantillas de CÃ³digo Listas](EVALUACION-VII-TRIMESTRE-PLANTILLAS-CODIGO.md)** â† **Copia y completa el cÃ³digo**
- **ğŸ“Š [RÃºbrica de EvaluaciÃ³n](EVALUACION-VII-TRIMESTRE-RUBRICA.md)** â† **CÃ³mo serÃ¡s evaluado**

### **Repositorio de Referencia**

- **Ruta:** `/01-fastapi/userservice` y `/01-fastapi/evalinservice`
- **DocumentaciÃ³n:** `_docs/` (especialmente historias de usuario y especificaciÃ³n de APIs)
- **Ejemplos:** CÃ³digo existente como referencia de implementaciÃ³n

### **Servicios a Trabajar**

- **UserService:** Sistema de autenticaciÃ³n y gestiÃ³n de usuarios (100% implementado)
- **EvalinService:** Sistema de evaluaciÃ³n de instructores (95% implementado)

### **âš¡ Quick Start**

1. **Lee primero:** [Instrucciones Detalladas](EVALUACION-VII-TRIMESTRE-INSTRUCCIONES-DETALLADAS.md)
2. **Usa las plantillas:** [Plantillas de CÃ³digo](EVALUACION-VII-TRIMESTRE-PLANTILLAS-CODIGO.md)
3. **Verifica con:** [RÃºbrica de EvaluaciÃ³n](EVALUACION-VII-TRIMESTRE-RUBRICA.md)

---

## ğŸ“‹ **ESTRUCTURA DE LA EVALUACIÃ“N**

### **PARTE 1: ANÃLISIS Y COMPRENSIÃ“N (20 puntos)**

#### **1.1 AnÃ¡lisis de Arquitectura (10 puntos)**

Analiza y documenta la arquitectura Clean Architecture implementada en ambos servicios:

**Entregables:**

1. **Diagrama de arquitectura** mostrando las 4 capas (Domain, Application, Infrastructure, Presentation)
2. **Documento de anÃ¡lisis** (mÃ¡ximo 2 pÃ¡ginas) que explique:
   - Responsabilidades de cada capa
   - Flujo de datos entre capas
   - Patrones de diseÃ±o identificados (Repository, Dependency Injection, etc.)
   - Ventajas de esta arquitectura vs arquitectura monolÃ­tica

**Criterios de evaluaciÃ³n:**

- PrecisiÃ³n en la identificaciÃ³n de responsabilidades
- Claridad en la explicaciÃ³n del flujo de datos
- IdentificaciÃ³n correcta de patrones de diseÃ±o

#### **1.2 AnÃ¡lisis de Casos de Uso (10 puntos)**

Selecciona 3 casos de uso (use cases) de cada servicio y documenta:

**Para cada caso de uso:**

1. **PropÃ³sito** y funcionalidad
2. **Entradas** y **salidas**
3. **Dependencias** (repositorios, servicios externos)
4. **Flujo de ejecuciÃ³n** paso a paso
5. **Manejo de errores** implementado

**Entregable:** Documento tÃ©cnico con el anÃ¡lisis completo

---

### **PARTE 2: IMPLEMENTACIÃ“N PRÃCTICA (50 puntos)**

#### **2.1 Implementar Nueva Funcionalidad en UserService (25 puntos)**

**Funcionalidad a implementar:** **Sistema de Preferencias de Usuario**

**Requerimientos:**

1. **Entidad Domain:** `UserPreferences`

   ```python
   # Campos requeridos:
   - user_id: UUID
   - language: str (es, en)
   - theme: str (light, dark, auto)
   - notifications_email: bool
   - notifications_push: bool
   - timezone: str
   - created_at: datetime
   - updated_at: datetime
   ```

2. **Endpoints a implementar:**

   ```python
   GET /api/v1/users/preferences        # Obtener preferencias del usuario autenticado
   PUT /api/v1/users/preferences        # Actualizar preferencias
   POST /api/v1/users/preferences/reset # Resetear a valores por defecto
   ```

3. **Casos de uso requeridos:**
   - `GetUserPreferencesUseCase`
   - `UpdateUserPreferencesUseCase`
   - `ResetUserPreferencesUseCase`

**Criterios de evaluaciÃ³n:**

- ImplementaciÃ³n completa de todas las capas
- Seguimiento de patrones establecidos
- Validaciones apropiadas
- Manejo de errores
- Tests unitarios (mÃ­nimo 80% coverage)

#### **2.2 Implementar Nueva Funcionalidad en EvalinService (25 puntos)**

**Funcionalidad a implementar:** **Sistema de Comentarios en Evaluaciones**

**Requerimientos:**

1. **Entidad Domain:** `EvaluationComment`

   ```python
   # Campos requeridos:
   - comment_id: UUID
   - evaluation_id: UUID
   - user_id: UUID (quien comenta)
   - comment_text: str
   - is_private: bool (solo visible para admin/coordinador)
   - created_at: datetime
   - updated_at: datetime
   ```

2. **Endpoints a implementar:**

   ```python
   POST /api/v1/evaluations/{evaluation_id}/comments    # Agregar comentario
   GET /api/v1/evaluations/{evaluation_id}/comments     # Listar comentarios
   PUT /api/v1/evaluations/comments/{comment_id}        # Editar comentario
   DELETE /api/v1/evaluations/comments/{comment_id}     # Eliminar comentario
   ```

3. **Reglas de negocio:**
   - Solo el autor puede editar/eliminar sus comentarios
   - Comentarios privados solo visibles para admin/coordinador
   - No se pueden agregar comentarios a evaluaciones cerradas

**Criterios de evaluaciÃ³n:**

- Correcta implementaciÃ³n de reglas de negocio
- IntegraciÃ³n con sistema de permisos existente
- Validaciones de seguridad
- Tests de integraciÃ³n

---

### **PARTE 3: INTEGRACIÃ“N Y COMUNICACIÃ“N ENTRE SERVICIOS (20 puntos)**

#### **3.1 Implementar ComunicaciÃ³n entre Servicios (20 puntos)**

**Funcionalidad a implementar:** **NotificaciÃ³n automÃ¡tica cuando se completa una evaluaciÃ³n**

**Requerimiento:**
Cuando un estudiante complete una evaluaciÃ³n en EvalinService, debe enviarse una notificaciÃ³n al UserService para registrar la actividad del usuario.

**ImplementaciÃ³n requerida:**

1. **En EvalinService:**

   ```python
   # Agregar notificaciÃ³n despuÃ©s de completar evaluaciÃ³n
   class NotifyUserActivityUseCase:
       async def execute(self, user_id: UUID, activity_data: dict):
           # Enviar datos a UserService
   ```

2. **En UserService:**

   ```python
   # Nuevo endpoint para recibir notificaciones de actividad
   POST /api/v1/users/activity-log

   # Entidad para almacenar actividades
   class UserActivity:
       - activity_id: UUID
       - user_id: UUID
       - service_source: str
       - activity_type: str
       - activity_data: dict
       - timestamp: datetime
   ```

**Criterios de evaluaciÃ³n:**

- ComunicaciÃ³n HTTP correcta entre servicios
- Manejo de errores de red
- Logging apropiado
- Tests de integraciÃ³n

---

### **PARTE 4: TESTING Y CALIDAD DE CÃ“DIGO (10 puntos)**

#### **4.1 Tests Unitarios y de IntegraciÃ³n (10 puntos)**

**Requerimientos:**

1. **Tests unitarios** para todos los casos de uso implementados
2. **Tests de integraciÃ³n** para los endpoints implementados
3. **Coverage mÃ­nimo:** 85% en las nuevas funcionalidades
4. **Tests de errores:** Validar manejo de excepciones

**Herramientas a usar:**

- `pytest` para testing
- `pytest-cov` para coverage
- `httpx` para tests de API

**Ejemplo de estructura de tests:**

```python
tests/
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ test_user_preferences_use_cases.py
â”‚   â””â”€â”€ test_evaluation_comment_use_cases.py
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ test_user_preferences_api.py
â”‚   â””â”€â”€ test_evaluation_comments_api.py
â””â”€â”€ test_service_communication.py
```

---

## ğŸš€ **EJERCICIOS PRÃCTICOS ADICIONALES**

### **Ejercicio 1: OptimizaciÃ³n de Consultas (Bonus: 5 puntos)**

Identifica y optimiza 2 consultas SQL en los servicios que podrÃ­an mejorar su rendimiento. Documenta:

- Consulta original
- Problema identificado
- SoluciÃ³n propuesta
- MediciÃ³n de mejora

### **Ejercicio 2: DocumentaciÃ³n API (Bonus: 5 puntos)**

Mejora la documentaciÃ³n Swagger de los nuevos endpoints con:

- Ejemplos de request/response
- CÃ³digos de error detallados
- Descripciones completas
- Tags y categorizaciÃ³n

### **Ejercicio 3: AnÃ¡lisis de Seguridad (Bonus: 5 puntos)**

Realiza un anÃ¡lisis de seguridad de las nuevas funcionalidades:

- ValidaciÃ³n de entrada
- AutorizaciÃ³n apropiada
- PrevenciÃ³n de ataques comunes (SQL injection, XSS, etc.)
- Recomendaciones de mejora

---

## ğŸ“ **ENTREGABLES Y CRONOGRAMA**

### **Cronograma Sugerido**

| DÃ­a         | Actividades                                 | Entregables            |
| ----------- | ------------------------------------------- | ---------------------- |
| **DÃ­a 1-2** | AnÃ¡lisis de arquitectura y casos de uso     | Documentos de anÃ¡lisis |
| **DÃ­a 3-4** | ImplementaciÃ³n UserService (Preferencias)   | CÃ³digo + Tests         |
| **DÃ­a 5-6** | ImplementaciÃ³n EvalinService (Comentarios)  | CÃ³digo + Tests         |
| **DÃ­a 7**   | IntegraciÃ³n servicios + DocumentaciÃ³n final | Proyecto completo      |

### **Formato de Entrega**

**Estructura del repositorio a entregar:**

```
apellido_nombre_evaluacion_vii/
â”œâ”€â”€ README.md                          # Instrucciones de instalaciÃ³n y ejecuciÃ³n
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ arquitectura_analisis.pdf      # Parte 1.1
â”‚   â”œâ”€â”€ casos_uso_analisis.pdf         # Parte 1.2
â”‚   â””â”€â”€ reflexiones_aprendizaje.pdf    # ReflexiÃ³n personal
â”œâ”€â”€ userservice/
â”‚   â”œâ”€â”€ app/domain/entities/user_preferences.py
â”‚   â”œâ”€â”€ app/application/use_cases/preferences_use_cases.py
â”‚   â”œâ”€â”€ app/infrastructure/repositories/preferences_repository.py
â”‚   â”œâ”€â”€ app/presentation/routers/preferences_router.py
â”‚   â””â”€â”€ tests/
â”œâ”€â”€ evalinservice/
â”‚   â”œâ”€â”€ app/domain/entities/evaluation_comment.py
â”‚   â”œâ”€â”€ app/application/use_cases/comment_use_cases.py
â”‚   â”œâ”€â”€ app/infrastructure/repositories/comment_repository.py
â”‚   â”œâ”€â”€ app/presentation/routers/comment_router.py
â”‚   â””â”€â”€ tests/
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ service_communication.py
â”‚   â””â”€â”€ tests/test_integration.py
â””â”€â”€ requirements.txt                   # Dependencias adicionales si las hay
```

---

## ğŸ† **CRITERIOS DE EVALUACIÃ“N**

### **RÃºbrica de CalificaciÃ³n**

| Aspecto              | Excelente (90-100%)                        | Bueno (80-89%)                             | Aceptable (70-79%)                           | Insuficiente (<70%)              |
| -------------------- | ------------------------------------------ | ------------------------------------------ | -------------------------------------------- | -------------------------------- |
| **Arquitectura**     | Comprende perfectamente Clean Architecture | Comprende conceptos principales            | Comprende parcialmente                       | No comprende la arquitectura     |
| **ImplementaciÃ³n**   | CÃ³digo profesional, patrones correctos     | CÃ³digo funcional con pequeÃ±os errores      | CÃ³digo funcional bÃ¡sico                      | CÃ³digo no funcional o incompleto |
| **Testing**          | Tests completos, >90% coverage             | Tests adecuados, >80% coverage             | Tests bÃ¡sicos, >70% coverage                 | Tests insuficientes o ausentes   |
| **Buenas PrÃ¡cticas** | CÃ³digo limpio, documentado, estÃ¡ndares     | CÃ³digo organizado, pocas inconsistencias   | CÃ³digo funcional con algunas malas prÃ¡cticas | CÃ³digo desorganizado             |
| **IntegraciÃ³n**      | ComunicaciÃ³n robusta entre servicios       | ComunicaciÃ³n funcional con errores menores | ComunicaciÃ³n bÃ¡sica                          | ComunicaciÃ³n no funcional        |

### **DistribuciÃ³n de Puntos**

- **Parte 1 (AnÃ¡lisis):** 20 puntos
- **Parte 2 (ImplementaciÃ³n):** 50 puntos
- **Parte 3 (IntegraciÃ³n):** 20 puntos
- **Parte 4 (Testing):** 10 puntos
- **Ejercicios Bonus:** Hasta 15 puntos adicionales

**Total:** 100 puntos + 15 bonus = 115 puntos mÃ¡ximo

---

## ğŸ’¡ **RECURSOS Y BUENAS PRÃCTICAS**

### **DocumentaciÃ³n de Referencia**

1. **Clean Architecture:** Revisar implementaciÃ³n en UserService
2. **FastAPI Docs:** https://fastapi.tiangolo.com/
3. **Pydantic:** Para validaciones y schemas
4. **SQLAlchemy:** Para modelos de base de datos
5. **Pytest:** Para testing

### **Buenas PrÃ¡cticas a Seguir**

1. **Nomenclatura:** Seguir convenciones PEP 8
2. **DocumentaciÃ³n:** Docstrings en funciones y clases
3. **Validaciones:** Usar Pydantic para validar entrada
4. **Errores:** Usar excepciones especÃ­ficas del domain
5. **Logging:** Implementar logs informativos
6. **Seguridad:** Validar permisos y autenticaciÃ³n

### **Comandos Ãštiles**

```bash
# Ejecutar tests con coverage
pytest --cov=app --cov-report=html

# Formatear cÃ³digo
black .

# Linting
flake8 .

# Ejecutar servicios
uvicorn main:app --reload --port 8001
```

---

## ğŸ“ **REFLEXIÃ“N FINAL**

**Pregunta de reflexiÃ³n (incluir en entrega):**

_"DespuÃ©s de trabajar con esta arquitectura y estos microservicios, reflexiona sobre las siguientes preguntas (mÃ¡ximo 1 pÃ¡gina):_

1. _Â¿QuÃ© ventajas y desventajas identificaste en la arquitectura Clean Architecture?_
2. _Â¿CÃ³mo contribuye esta experiencia a tu formaciÃ³n como desarrollador backend?_
3. _Â¿QuÃ© aspectos te resultaron mÃ¡s desafiantes y cÃ³mo los superaste?_
4. _Â¿CÃ³mo aplicarÃ­as estos conocimientos en un proyecto real de la industria?"_

---

**Â¡Ã‰xito en tu evaluaciÃ³n! Recuerda que este es un ejercicio de aprendizaje profesional que te prepararÃ¡ para la industria del desarrollo de software.**
